### **Chapter 6. 똑똑한 AI 만들기: 지도학습 AI 모델링 기초**

**(챕터 소개 - 비전공자 눈높이)**

안녕하세요! 이번 챕터에서는 인공지능이 '학습'하는 방식 중 하나인 **지도학습(Supervised Learning)**에 대해 알아볼 거예요. '지도학습'은 마치 우리가 정답이 있는 문제집을 풀면서 공부하는 것과 비슷해요. AI에게 '이런 데이터가 들어오면, 정답은 이거야!'라고 알려주면서 똑똑하게 만드는 방법이죠.

예를 들어, 스팸 메일 필터를 만든다고 해볼까요? AI에게 어떤 메일이 스팸이고 어떤 메일이 정상인지 미리 알려주고 학습시키면, AI는 새로운 메일이 왔을 때 스팸인지 아닌지 구분할 수 있게 됩니다. 또는 집 크기 데이터를 보고 집값을 예측하는 것도 지도학습의 한 종류랍니다.

이번 챕터에서는 파이썬의 **'사이킷런(Scikit-learn)'**이라는 아주 편리한 도구 상자를 이용해서, 여러 가지 지도학습 방법들을 직접 체험해 볼 거예요. 숫자 값을 예측하는 **회귀(Regression)** 방법부터, 데이터를 몇 개의 그룹으로 나누는 **분류(Classification)** 방법, 그리고 여러 개의 모델을 합쳐 더 강력한 예측을 하는 **앙상블(Ensemble)** 기법까지! 코드를 직접 실행해보면서 AI 모델이 어떻게 만들어지는지 감을 잡아보는 것이 목표예요. 마지막에는 어떤 모델이 더 좋은지 비교하는 방법도 살짝 알아볼게요. 겁먹지 말고 차근차근 따라와 보세요!

---

#### **1. 사이킷런 라이브러리: AI 모델링을 위한 만능 도구 상자**

**사이킷런(Scikit-learn)**은 파이썬으로 인공지능 모델을 만들 때 가장 많이 사용하는 **필수 도구(라이브러리)**예요. 마치 요리할 때 필요한 온갖 도구가 담긴 '만능 조리도구 세트' 같다고 생각하면 쉬워요.

**왜 사이킷런을 사용할까요?**

* **간편함:** 복잡한 AI 알고리즘들을 몇 줄의 코드로 쉽게 사용할 수 있게 미리 만들어 놨어요.
* **다양한 기능:** 데이터를 준비하고(다듬고), 모델을 만들고(학습시키고), 모델이 얼마나 잘하는지 평가하는(성능 확인) 모든 과정에 필요한 도구들이 들어있어요.
* **인기:** 전 세계 수많은 개발자와 데이터 과학자들이 사용하고 있어서, 관련 자료나 도움을 얻기도 쉬워요.

이번 챕터에서 배울 모든 AI 모델들은 이 '사이킷런'이라는 도구 상자를 이용해서 만들 거예요. 이제부터 이 도구 상자 안의 멋진 연장들을 하나씩 꺼내 사용법을 배워봅시다!

---

#### **2. 선형 회귀: 점들을 가장 잘 설명하는 직선 찾기**

**선형 회귀(Linear Regression)**는 가장 기본적이면서도 많이 쓰이는 예측 방법이에요. 마치 흩어져 있는 점들(데이터)을 보고, 이 점들을 가장 잘 관통하는 **하나의 직선**을 긋는 것과 같아요. 이 직선을 이용하면 새로운 점이 어디쯤 찍힐지 예측할 수 있죠.

**핵심 아이디어:**

* **데이터:** '집 크기(X)'처럼 예측에 사용할 정보와 '집값(Y)'처럼 예측하고 싶은 **숫자 값** 데이터가 필요해요.
* **목표:** 집 크기가 변할 때 집값이 어떻게 변하는지를 나타내는 **최적의 직선** 방정식을 찾는 거예요. (y = ax + b 에서 가장 적절한 a와 b 찾기)
* **예측:** 이 직선을 이용하면, 새로운 집 크기(X)가 주어졌을 때 예상 집값(Y)을 계산할 수 있어요.

**언제 사용할까요?**

* 집 크기, 방 개수 등으로 **집값 예측**하기
* 광고비 지출액으로 다음 달 **매출액 예측**하기
* 공부 시간으로 **시험 점수 예측**하기 등 **숫자 값을 예측**할 때 사용해요.

**[파이썬 코드 실습]**

```python
import numpy as np
from sklearn.linear_model import LinearRegression

# 1. 데이터 준비 (X: 공부 시간, y: 시험 점수)
# 공부 시간 데이터를 2차원 배열 형태로 만듭니다. (사이킷런 요구사항)
X = np.array([[2], [4], [6], [8]]) # 2시간, 4시간, 6시간, 8시간 공부
y = np.array([40, 60, 70, 90])    # 해당 점수

# 2. 모델 선택 및 학습
model = LinearRegression() # 선형 회귀 모델 도구 꺼내기
model.fit(X, y)           # 문제집(X)과 정답(y)으로 모델 학습시키기!

# 3. 예측
# 5시간 공부했을 때 예상 점수는?
new_X = np.array([[5]])
predicted_score = model.predict(new_X)

print(f"공부 시간: {X.flatten()}")
print(f"시험 점수: {y}")
print(f"5시간 공부했을 때 예상 점수: {predicted_score[0]:.2f} 점")

# (참고) 모델이 찾은 직선의 기울기(a)와 절편(b) 확인
# print(f"기울기 (a): {model.coef_[0]:.2f}")
# print(f"y절편 (b): {model.intercept_:.2f}")
```

**(코드 설명)**

1.  필요한 도구(`numpy` 숫자 계산용, `LinearRegression` 모델)를 불러옵니다.
2.  간단한 공부 시간(X)과 시험 점수(y) 데이터를 만듭니다. X는 2차원 배열 `[[값]]` 형태여야 합니다.
3.  `LinearRegression()` 모델을 만들고, `fit(X, y)` 함수로 모델을 학습시킵니다.
4.  `predict()` 함수에 새로운 공부 시간 `[[5]]`를 넣어 예상 점수를 예측하고 출력합니다.

---

#### **3. 로지스틱 회귀: 예/아니오, 둘 중 하나로 분류하기**

**로지스틱 회귀(Logistic Regression)**는 이름과 달리, 숫자 값을 예측하는 게 아니라 데이터를 **두 그룹 중 하나로 분류(Classification)**할 때 주로 사용돼요. 예를 들어, 이메일 내용을 보고 '스팸'인지 '정상'인지, 공부 시간을 보고 '합격'인지 '불합격'인지 나누는 거죠.

**핵심 아이디어:**

* **목표:** 데이터가 특정 그룹(예: '합격' 또는 '스팸')에 속할 **확률(0~1 사이 값)**을 계산해요.
* **결정:** 계산된 확률이 **정해진 기준(보통 0.5)**보다 높으면 '합격/스팸', 낮으면 '불합격/정상'으로 분류해요.
* **시그모이드 함수:** 확률을 계산하기 위해 '시그모이드'라는 특별한 함수를 사용해요. 이 함수는 어떤 숫자가 들어오든 0과 1 사이의 값으로 바꿔주는 역할을 해요.

**언제 사용할까요?**

* 이메일이 **스팸/정상**인지 분류하기
* 공부 시간, 출석률 등으로 **합격/불합격** 예측하기
* 고객 정보로 **이탈/유지** 고객 분류하기 등 **두 가지 중 하나로 나누는 문제**에 사용해요.

**[파이썬 코드 실습]**

```python
import numpy as np
from sklearn.linear_model import LogisticRegression

# 1. 데이터 준비 (X: 공부 시간, y: 합격 여부 (0: 불합격, 1: 합격))
X = np.array([[1], [2], [5], [6], [7], [9]]) # 공부 시간
y = np.array([0, 0, 0, 1, 1, 1])           # 1~5시간은 불합격(0), 6시간 이상은 합격(1)

# 2. 모델 선택 및 학습
model = LogisticRegression() # 로지스틱 회귀 모델 도구 꺼내기
model.fit(X, y)            # 모델 학습시키기!

# 3. 예측
# 4시간 공부했을 때와 8시간 공부했을 때 합격 여부는?
new_X = np.array([[4], [8]])
predicted_pass = model.predict(new_X)

print(f"공부 시간: {X.flatten()}")
print(f"합격 여부: {y}")
print(f"4시간 공부 시 예상 합격 여부 (0: 불합격, 1: 합격): {predicted_pass[0]}")
print(f"8시간 공부 시 예상 합격 여부 (0: 불합격, 1: 합격): {predicted_pass[1]}")

# (참고) 각 클래스(0, 1)에 속할 확률 확인
# predicted_proba = model.predict_proba(new_X)
# print(f"\n[4시간, 8시간] 공부 시 [불합격(0), 합격(1)] 확률:\n{predicted_proba}")
```

**(코드 설명)**

1.  필요한 도구를 불러옵니다. (`LogisticRegression` 사용)
2.  공부 시간(X)과 합격 여부(y) 데이터를 만듭니다. y는 0(불합격) 또는 1(합격)입니다.
3.  `LogisticRegression()` 모델을 만들고 `fit(X, y)`로 학습시킵니다.
4.  `predict()` 함수로 4시간과 8시간 공부했을 때의 합격 여부를 예측하고 출력합니다. (`predict_proba`를 쓰면 각 그룹에 속할 확률도 볼 수 있어요!)

---

#### **4. 의사결정나무: '스무고개' 하듯 질문하며 답 찾기**

**의사결정나무(Decision Tree)**는 마치 '스무고개' 놀이처럼, 데이터에 대해 **질문을 던져가며 답을 찾아가는** 방식의 모델이에요. 질문에 따라 데이터를 나누다 보면 나무(Tree) 모양의 구조가 만들어지죠.

**핵심 아이디어:**

* **질문과 분류:** 가장 처음에 모든 데이터를 가지고 시작해서(뿌리 노드), 가장 데이터를 잘 나눌 수 있는 질문(예: "공부 시간이 5시간 이상인가?")을 찾아요.
* **가지치기:** 질문의 답("예" 또는 "아니오")에 따라 데이터를 두 그룹으로 나누고(가지 뻗기), 각 그룹에 대해 또 최적의 질문을 찾아 나누는 과정을 반복해요.
* **최종 결정:** 더 이상 질문이 필요 없거나(모든 데이터가 같은 그룹이 됨) 정해진 깊이에 도달하면(잎 노드), 해당 그룹의 최종 결론(예: "합격", "불합격")을 내립니다.

**언제 사용할까요?**

* **결정 과정을 이해하기 쉬워야 할 때** 좋아요. 나무 그림을 보면 왜 그런 결정을 내렸는지 알 수 있거든요.
* 고객 유형 분류, 대출 신청 승인/거절 결정 등 **분류** 문제와 **숫자 예측(회귀)** 문제 모두에 사용할 수 있어요.

**[파이썬 코드 실습]**

```python
import numpy as np
from sklearn.tree import DecisionTreeClassifier
# (선택) 나무 구조를 그림으로 보려면 graphviz 라이브러리 설치 및 설정이 필요해요.
# from sklearn.tree import export_graphviz
# import graphviz

# 1. 데이터 준비 (X: [공부 시간, 잠자는 시간], y: 성적 그룹 (0: Low, 1: Mid, 2: High))
X = np.array([[2, 8], [4, 7], [6, 6], [8, 5], [7, 8], [9, 7]]) # [공부, 잠] 시간
y = np.array([0, 0, 1, 1, 2, 2])                              # 성적 그룹

# 2. 모델 선택 및 학습
model = DecisionTreeClassifier(random_state=42) # 의사결정나무 모델 (분류용)
                                               # random_state는 실행할 때마다 같은 결과를 보기 위함
model.fit(X, y)

# 3. 예측
# [5시간 공부, 7시간 잠] vs [3시간 공부, 6시간 잠] 학생의 성적 그룹은?
new_X = np.array([[5, 7], [3, 6]])
predicted_grade = model.predict(new_X)

print(f"데이터 (X): \n{X}")
print(f"성적 그룹 (y): {y}")
print(f"[5시간 공부, 7시간 잠] 예상 성적 그룹 (0:Low, 1:Mid, 2:High): {predicted_grade[0]}")
print(f"[3시간 공부, 6시간 잠] 예상 성적 그룹 (0:Low, 1:Mid, 2:High): {predicted_grade[1]}")

# (선택) 의사결정나무 구조 시각화 (graphviz 설치 필요)
# dot_data = export_graphviz(model, out_file=None,
#                            feature_names=['Study Hours', 'Sleep Hours'],
#                            class_names=['Low', 'Mid', 'High'],
#                            filled=True, rounded=True, special_characters=True)
# graph = graphviz.Source(dot_data)
# graph.render("decision_tree_grades") # decision_tree_grades.pdf 파일로 저장됨
# print("\n의사결정나무 구조가 'decision_tree_grades.pdf' 파일로 저장되었습니다.")
```

**(코드 설명)**

1.  필요한 도구를 불러옵니다. (`DecisionTreeClassifier` 사용)
2.  공부 시간과 잠자는 시간(X, 2개의 특징 사용)과 성적 그룹(y, 3개 그룹) 데이터를 만듭니다.
3.  `DecisionTreeClassifier()` 모델을 만들고 `fit(X, y)`로 학습시킵니다. `random_state`는 나무를 만들 때 무작위성이 들어가는데, 이 값을 고정하면 매번 같은 모양의 나무가 만들어져서 결과를 비교하기 좋아요.
4.  `predict()` 함수로 새로운 학생 데이터에 대한 성적 그룹을 예측하고 출력합니다.
5.  (선택 사항) `graphviz` 라이브러리가 설치되어 있다면, 학습된 나무 구조를 그림 파일로 저장해서 볼 수 있어요. 어떤 질문으로 데이터가 나뉘는지 시각적으로 확인할 수 있습니다.

---

#### **5. 앙상블 모델: 여러 명의 지혜를 모아 더 똑똑하게!**

**앙상블(Ensemble)**은 혼자보다 **여럿이 힘을 합치면 더 낫다**는 아이디어에서 출발한 기법이에요. **여러 개의 작은 AI 모델(약한 학습기)**을 만들고, 그 모델들의 예측 결과를 **종합**해서 최종 결정을 내리는 방식이죠. 한 명의 전문가보다 여러 전문가의 의견을 듣는 것이 더 정확할 수 있는 것과 같아요.

**왜 사용할까요?**

* 하나의 모델만 사용할 때 발생할 수 있는 **실수나 편견을 줄여줘요.**
* 모델 각각의 약점은 서로 보완하고 장점은 살려서, **전체적으로 더 정확하고 안정적인 예측**을 할 수 있어요.

**대표적인 앙상블 방법:**

* **배깅(Bagging):** 여러 모델이 **독립적으로** 각자 예측하고, 그 결과를 **투표(분류)**하거나 **평균(회귀)**내서 최종 답을 정해요. (예: 랜덤 포레스트)
* **부스팅(Boosting):** 모델들이 **순서대로** 등장해요. 앞 모델이 실수한 부분을 다음 모델이 집중적으로 학습해서 **점점 더 똑똑해지는** 방식이에요. (예: 그래디언트 부스팅)

앙상블 모델은 많은 실제 AI 서비스나 데이터 분석 대회에서 아주 좋은 성능을 보여주는 강력한 방법이랍니다.

---

#### **6. 랜덤 포레스트 모델: 나무들이 모여 숲을 이루다!**

**랜덤 포레스트(Random Forest)**는 이름처럼 **많은 의사결정나무(Tree)들이 모여 숲(Forest)을 이룬** 모델이에요. 위에서 설명한 앙상블 기법 중 **배깅(Bagging)** 방식을 사용하죠.

**핵심 아이디어:**

1.  **데이터 일부 + 질문 일부만 사용:** 전체 데이터 중 일부만 **무작위로 뽑고**, 질문할 수 있는 특징(예: 공부 시간, 잠자는 시간) 중에서도 **일부만 무작위로 골라서** 각각의 나무를 만들어요. 이렇게 하면 나무들이 서로 조금씩 다른 모양과 특성을 갖게 돼요. (다양성 확보!)
2.  **독립적인 학습:** 이렇게 뽑힌 데이터와 특징으로 **여러 개의 의사결정나무**를 각각 독립적으로 학습시켜요.
3.  **의견 종합:** 새로운 데이터가 들어오면, 숲 속의 **모든 나무에게 물어봐요.**
    * **분류 문제:** 가장 많은 나무가 선택한 답(투표 결과)을 최종 답으로 정해요.
    * **숫자 예측 문제:** 모든 나무가 예측한 숫자들의 평균값을 최종 답으로 정해요.

**왜 좋을까요?**

* 나무 하나만 쓸 때 생기기 쉬운 **과적합(학습 데이터에만 너무 잘 맞고 새로운 데이터에는 잘 못하는 현상) 문제를 크게 줄여줘요.**
* 일반적으로 **매우 정확한 예측**을 하고, 데이터가 좀 이상해도(이상치) 크게 흔들리지 않아요.

**[파이썬 코드 실습]**

```python
import numpy as np
from sklearn.ensemble import RandomForestClassifier # 랜덤 포레스트 분류 모델 사용

# 1. 데이터 준비 (의사결정나무 예제와 동일)
X = np.array([[2, 8], [4, 7], [6, 6], [8, 5], [7, 8], [9, 7]]) # [공부, 잠] 시간
y = np.array([0, 0, 1, 1, 2, 2])                              # 성적 그룹 (0: Low, 1: Mid, 2: High)

# 2. 모델 선택 및 학습
# n_estimators: 숲을 구성할 나무의 개수 (예: 100개)
# random_state는 실행할 때마다 같은 결과를 보기 위함
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X, y)

# 3. 예측
# [5시간 공부, 7시간 잠] vs [3시간 공부, 6시간 잠] 학생의 성적 그룹은?
new_X = np.array([[5, 7], [3, 6]])
predicted_grade = model.predict(new_X)

print(f"데이터 (X): \n{X}")
print(f"성적 그룹 (y): {y}")
print(f"(랜덤 포레스트) [5시간 공부, 7시간 잠] 예상 성적 그룹: {predicted_grade[0]}")
print(f"(랜덤 포레스트) [3시간 공부, 6시간 잠] 예상 성적 그룹: {predicted_grade[1]}")
```

**(코드 설명)**

1.  필요한 도구를 불러옵니다. (`RandomForestClassifier` 사용)
2.  의사결정나무 예제와 같은 데이터를 사용합니다.
3.  `RandomForestClassifier()` 모델을 만듭니다. `n_estimators=100`은 100개의 나무를 만들겠다는 뜻이에요. `fit(X, y)`로 학습시킵니다.
4.  `predict()` 함수로 예측하고 결과를 출력합니다. 사용법은 의사결정나무와 거의 동일하지만, 내부적으로는 100개의 나무가 예측한 결과를 종합한 것입니다.

---

#### **7. 그래디언트 부스팅: 실수로부터 배워 더 강해지다!**

**그래디언트 부스팅(Gradient Boosting)**도 여러 개의 모델을 사용하는 **앙상블** 기법인데, 랜덤 포레스트와는 다른 **부스팅(Boosting)** 방식을 사용해요. 마치 팀 프로젝트를 할 때, 첫 사람이 초안을 만들면, 다음 사람이 그 초안의 부족한 점을 보완하고, 또 다음 사람이 그 결과물의 부족한 점을 보완해나가면서 최종 결과물을 점점 더 완벽하게 만드는 것과 비슷해요.

**핵심 아이디어:**

1.  **첫 모델의 실수 확인:** 일단 간단한 첫 모델이 예측을 해요. 그리고 실제 정답과 얼마나 차이가 나는지(실수, 오류)를 계산해요.
2.  **실수 줄이기 학습:** 다음 모델은 이 '실수'를 예측하도록 학습해요. 즉, 앞 모델이 뭘 틀렸는지 배우는 거죠.
3.  **점진적 개선:** 이런 식으로 모델들을 **순서대로** 계속 추가하면서, 앞 모델들이 놓친 부분을 다음 모델들이 채워나가며 전체 예측 성능을 점차 높여가요.

**왜 좋을까요?**

* 잘 조정하면 랜덤 포레스트보다 **더 정확한 예측**을 할 때가 많아요. 많은 데이터 분석 대회에서 우승자들이 이 그래디언트 부스팅 계열의 모델들을 사용해요.
* 하지만, 랜덤 포레스트보다 **조금 더 세심한 설정(튜닝)**이 필요하고, 잘못하면 오히려 성능이 나빠지거나(과적합) 학습 시간이 오래 걸릴 수 있어요.

**[파이썬 코드 실습]**

```python
import numpy as np
from sklearn.ensemble import GradientBoostingClassifier # 그래디언트 부스팅 분류 모델 사용

# 1. 데이터 준비 (의사결정나무/랜덤 포레스트 예제와 동일)
X = np.array([[2, 8], [4, 7], [6, 6], [8, 5], [7, 8], [9, 7]]) # [공부, 잠] 시간
y = np.array([0, 0, 1, 1, 2, 2])                              # 성적 그룹 (0: Low, 1: Mid, 2: High)

# 2. 모델 선택 및 학습
# n_estimators: 만들 모델(나무)의 개수
# learning_rate: 앞 모델의 실수를 얼마나 반영할지 조절 (너무 크면 불안정, 너무 작으면 느림)
# random_state는 실행할 때마다 같은 결과를 보기 위함
model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
model.fit(X, y)

# 3. 예측
# [5시간 공부, 7시간 잠] vs [3시간 공부, 6시간 잠] 학생의 성적 그룹은?
new_X = np.array([[5, 7], [3, 6]])
predicted_grade = model.predict(new_X)

print(f"데이터 (X): \n{X}")
print(f"성적 그룹 (y): {y}")
print(f"(그래디언트 부스팅) [5시간 공부, 7시간 잠] 예상 성적 그룹: {predicted_grade[0]}")
print(f"(그래디언트 부스팅) [3시간 공부, 6시간 잠] 예상 성적 그룹: {predicted_grade[1]}")
```

**(코드 설명)**

1.  필요한 도구를 불러옵니다. (`GradientBoostingClassifier` 사용)
2.  이전 예제와 같은 데이터를 사용합니다.
3.  `GradientBoostingClassifier()` 모델을 만듭니다. `n_estimators`는 모델 개수, `learning_rate`는 학습 속도(?)와 관련된 중요한 설정값이에요. `fit(X, y)`로 학습시킵니다.
4.  `predict()` 함수로 예측하고 결과를 출력합니다. 사용법은 비슷하지만, 내부 동작 방식은 랜덤 포레스트와 다릅니다.

---

#### **8. 모델 간 성능 비교: 어떤 AI가 더 잘했을까? 성적표 매겨보기!**

여러 가지 방법으로 AI 모델을 만들었다면, 이제 **어떤 모델이 가장 일을 잘하는지 평가**해봐야겠죠? 마치 시험을 보고 성적표를 매기는 것과 같아요. 어떤 기준으로 점수를 매겨야 공정하고 정확하게 평가할 수 있을까요?

**왜 평가가 중요할까요?**

* 단순히 "만들었다"에서 끝나는 게 아니라, **실제로 도움이 되는 모델인지 확인**해야 해요.
* 여러 모델 중 **가장 성능 좋은 모델을 선택**해서 사용해야 더 좋은 결과를 얻을 수 있어요.

**평가 방법 (맛보기):**

* **숫자 예측(회귀) 모델 평가:**
    * **오차 확인:** 모델이 예측한 숫자와 실제 정답 숫자가 평균적으로 얼마나 차이 나는지 계산해요. (MAE, MSE, RMSE 같은 지표 사용) 차이가 적을수록 좋은 모델!
    * **설명력 확인 (R²):** 모델이 데이터의 변화를 얼마나 잘 설명하는지 점수(0~1점)로 나타내요. 1점에 가까울수록 좋아요.
* **분류(Classification) 모델 평가:**
    * **정확도(Accuracy):** 전체 문제 중에서 몇 개나 맞혔는지 비율을 봐요. (예: 100문제 중 90개 맞히면 정확도 90%) 가장 쉽지만, 데이터 쏠림(한쪽 답만 너무 많을 때)이 있으면 믿기 어려울 수 있어요.
    * **정밀도(Precision) & 재현율(Recall):**
        * 정밀도: "AI가 스팸이라고 한 메일 중 진짜 스팸은 몇 개?" (AI 예측의 정확성)
        * 재현율: "실제 스팸 메일 중에서 AI가 스팸이라고 찾아낸 건 몇 개?" (빠뜨리지 않고 잘 찾아냈는지)
        * 상황에 따라 둘 중 뭐가 더 중요한지 달라져요. (예: 병 진단에서는 실제 환자를 놓치지 않는 재현율이 더 중요할 수 있음)
    * **F1 점수:** 정밀도와 재현율을 모두 고려한 종합 점수예요.

**[파이썬 코드 실습 - 분류 모델 정확도 평가]**

```python
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score # 정확도 평가 도구 불러오기

# 1. 데이터 준비
X = np.array([[2, 8], [4, 7], [6, 6], [8, 5], [7, 8], [9, 7]])
y = np.array([0, 0, 1, 1, 2, 2])

# 2. 모델 학습 (의사결정나무와 랜덤 포레스트)
dt_model = DecisionTreeClassifier(random_state=42)
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

dt_model.fit(X, y)
rf_model.fit(X, y)

# 3. 학습 데이터에 대한 예측 수행
dt_pred = dt_model.predict(X)
rf_pred = rf_model.predict(X)

# 4. 성능 평가 (정확도 비교)
# accuracy_score(실제 정답, 모델의 예측)
dt_accuracy = accuracy_score(y, dt_pred)
rf_accuracy = accuracy_score(y, rf_pred)

print(f"학습 데이터: \n{X}")
print(f"실제 정답 (y): {y}")
print(f"의사결정나무 예측: {dt_pred}")
print(f"랜덤 포레스트 예측: {rf_pred}")
print(f"\n의사결정나무 정확도: {dt_accuracy:.4f}") # 소수점 4자리까지 출력
print(f"랜덤 포레스트 정확도: {rf_accuracy:.4f}")

# 주의: 실제로는 모델 성능을 제대로 평가하려면 학습에 사용하지 않은
# 별도의 테스트 데이터로 평가하거나, 교차 검증(Cross-Validation)을 사용해야 합니다!
# 여기서는 간단히 학습 데이터에 대한 정확도만 확인해 보았습니다.
```

**(코드 설명)**

1.  필요한 도구(`accuracy_score` 추가)와 데이터를 준비합니다.
2.  의사결정나무와 랜덤 포레스트 모델을 각각 학습시킵니다.
3.  학습에 사용했던 데이터(X)를 그대로 넣어서 각 모델의 예측값(`dt_pred`, `rf_pred`)을 얻습니다.
4.  `accuracy_score()` 함수에 실제 정답(`y`)과 각 모델의 예측값을 넣어 정확도를 계산하고 비교합니다.
5.  **중요:** 코드 마지막의 주의 문구처럼, 실제 모델 평가는 학습에 쓰지 않은 새로운 데이터로 해야 더 정확해요! 여기서는 코드 시연을 위해 간단히 보여준 것입니다.

---

**(챕터 마무리 - 비전공자 눈높이)**

와! 이번 챕터에서는 AI가 학습하는 방법 중 하나인 '지도학습'에 대해 알아보고, 여러 가지 모델들을 직접 코드로 만들어봤어요. 점들을 보고 직선을 그리는 **선형 회귀**, 예/아니오로 나누는 **로지스틱 회귀**, 스무고개 같은 **의사결정나무**, 그리고 여러 모델의 힘을 합친 **랜덤 포레스트**와 **그래디언트 부스팅**까지! 생각보다 어렵지 않았죠? (조금 어려웠어도 괜찮아요!)

가장 중요한 것은 **사이킷런**이라는 도구 덕분에 이런 모델들을 생각보다 쉽게 만들고 시험해 볼 수 있다는 거예요. 그리고 어떤 모델이 더 좋은지는 **정확도** 같은 '성적표'를 통해 비교할 수 있다는 것도 알게 되었죠.

물론 오늘 배운 내용은 AI 모델링의 아주 기초적인 부분이에요. 하지만 이 경험을 바탕으로 앞으로 AI를 좀 더 친근하게 느끼고, 어떤 원리로 작동하는지 어렴풋이나마 감을 잡으셨기를 바랍니다. 직접 코드를 바꿔가며 이것저것 실험해보는 것도 좋은 공부가 될 거예요! 다음 시간에는 [다음 챕터 주제, 예: 라벨 없는 데이터로 AI 학습시키기(비지도 학습) 또는 AI 모델 똑똑하게 만드는 비법(모델 튜닝)]에 대해 알아볼게요. 수고 많으셨습니다!
